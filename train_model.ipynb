{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c29c86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def72564",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Faizaan Ali Baig\\its me\\IABAC\\INX_Project\\data\\Processed\\pre_processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d71216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>EducationBackground</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>EmpDepartment</th>\n",
       "      <th>EmpJobRole</th>\n",
       "      <th>BusinessTravelFrequency</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>EmpEducationLevel</th>\n",
       "      <th>EmpEnvironmentSatisfaction</th>\n",
       "      <th>...</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>EmpWorkLifeBalance</th>\n",
       "      <th>ExperienceYearsAtThisCompany</th>\n",
       "      <th>ExperienceYearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>PerformanceRating</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Age  EducationBackground  MaritalStatus  EmpDepartment  \\\n",
       "0           0   32                    3              2              6   \n",
       "1           1   47                    3              2              6   \n",
       "2           2   40                    5              3              6   \n",
       "3           3   41                    0              1              3   \n",
       "4           4   60                    3              2              6   \n",
       "\n",
       "   EmpJobRole  BusinessTravelFrequency  DistanceFromHome  EmpEducationLevel  \\\n",
       "0          18                        2                10                  3   \n",
       "1          18                        2                14                  4   \n",
       "2          18                        1                 5                  4   \n",
       "3          11                        2                10                  4   \n",
       "4          18                        2                16                  4   \n",
       "\n",
       "   EmpEnvironmentSatisfaction  ...  TrainingTimesLastYear  EmpWorkLifeBalance  \\\n",
       "0                           4  ...                      2                   2   \n",
       "1                           4  ...                      2                   3   \n",
       "2                           4  ...                      2                   3   \n",
       "3                           2  ...                      2                   2   \n",
       "4                           1  ...                      1                   3   \n",
       "\n",
       "   ExperienceYearsAtThisCompany  ExperienceYearsInCurrentRole  \\\n",
       "0                            10                             7   \n",
       "1                             7                             7   \n",
       "2                            18                            13   \n",
       "3                            21                             6   \n",
       "4                             2                             2   \n",
       "\n",
       "   YearsSinceLastPromotion  YearsWithCurrManager  Attrition  \\\n",
       "0                        0                     8          1   \n",
       "1                        1                     7          1   \n",
       "2                        1                    12          1   \n",
       "3                       12                     6          1   \n",
       "4                        2                     2          1   \n",
       "\n",
       "   PerformanceRating  Female  Male  \n",
       "0                  3       0     1  \n",
       "1                  3       0     1  \n",
       "2                  4       0     1  \n",
       "3                  3       0     1  \n",
       "4                  3       0     1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47cbccf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1200 entries, 0 to 1199\n",
      "Data columns (total 29 columns):\n",
      " #   Column                        Non-Null Count  Dtype\n",
      "---  ------                        --------------  -----\n",
      " 0   Unnamed: 0                    1200 non-null   int64\n",
      " 1   Age                           1200 non-null   int64\n",
      " 2   EducationBackground           1200 non-null   int64\n",
      " 3   MaritalStatus                 1200 non-null   int64\n",
      " 4   EmpDepartment                 1200 non-null   int64\n",
      " 5   EmpJobRole                    1200 non-null   int64\n",
      " 6   BusinessTravelFrequency       1200 non-null   int64\n",
      " 7   DistanceFromHome              1200 non-null   int64\n",
      " 8   EmpEducationLevel             1200 non-null   int64\n",
      " 9   EmpEnvironmentSatisfaction    1200 non-null   int64\n",
      " 10  EmpHourlyRate                 1200 non-null   int64\n",
      " 11  EmpJobInvolvement             1200 non-null   int64\n",
      " 12  EmpJobLevel                   1200 non-null   int64\n",
      " 13  EmpJobSatisfaction            1200 non-null   int64\n",
      " 14  NumCompaniesWorked            1200 non-null   int64\n",
      " 15  OverTime                      1200 non-null   int64\n",
      " 16  EmpLastSalaryHikePercent      1200 non-null   int64\n",
      " 17  EmpRelationshipSatisfaction   1200 non-null   int64\n",
      " 18  TotalWorkExperienceInYears    1200 non-null   int64\n",
      " 19  TrainingTimesLastYear         1200 non-null   int64\n",
      " 20  EmpWorkLifeBalance            1200 non-null   int64\n",
      " 21  ExperienceYearsAtThisCompany  1200 non-null   int64\n",
      " 22  ExperienceYearsInCurrentRole  1200 non-null   int64\n",
      " 23  YearsSinceLastPromotion       1200 non-null   int64\n",
      " 24  YearsWithCurrManager          1200 non-null   int64\n",
      " 25  Attrition                     1200 non-null   int64\n",
      " 26  PerformanceRating             1200 non-null   int64\n",
      " 27  Female                        1200 non-null   int64\n",
      " 28  Male                          1200 non-null   int64\n",
      "dtypes: int64(29)\n",
      "memory usage: 272.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0007adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into dependent and independent variable.\n",
    "x = data.drop('PerformanceRating',axis=1)\n",
    "y = data['PerformanceRating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d1bc35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 874, 4: 874, 2: 874})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE()\n",
    "from collections import Counter\n",
    "x,y = sm.fit_resample(x,y)\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe7a23fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test= train_test_split(x,y,random_state=42,stratify=y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89af87a9",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a2e03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(x_train,y_train)\n",
    "y_pred_dtc = dtc.predict(x_test)\n",
    "y_pred_dtctrain = dtc.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47361f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.95      0.96      0.95       175\n",
      "           3       0.92      0.91      0.92       175\n",
      "           4       0.94      0.95      0.95       175\n",
      "\n",
      "    accuracy                           0.94       525\n",
      "   macro avg       0.94      0.94      0.94       525\n",
      "weighted avg       0.94      0.94      0.94       525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,y_pred_dtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2906138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00       699\n",
      "           3       1.00      1.00      1.00       699\n",
      "           4       1.00      1.00      1.00       699\n",
      "\n",
      "    accuracy                           1.00      2097\n",
      "   macro avg       1.00      1.00      1.00      2097\n",
      "weighted avg       1.00      1.00      1.00      2097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training score \n",
    "print(classification_report(y_train,y_pred_dtctrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6968b2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27436 candidates, totalling 137180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "72200 fits failed out of a total of 137180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8578 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\tree\\_classes.py\", line 889, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\tree\\_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeClassifier must be a str among {'entropy', 'log_loss', 'gini'}. Got 'ginni' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8578 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\tree\\_classes.py\", line 889, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\tree\\_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeClassifier must be a str among {'entropy', 'gini', 'log_loss'}. Got 'ginni' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "17122 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\tree\\_classes.py\", line 889, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\tree\\_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeClassifier must be a str among {'log_loss', 'entropy', 'gini'}. Got 'ginni' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25734 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\tree\\_classes.py\", line 889, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\tree\\_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeClassifier must be a str among {'gini', 'log_loss', 'entropy'}. Got 'ginni' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8578 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\tree\\_classes.py\", line 889, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\tree\\_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeClassifier must be a str among {'log_loss', 'gini', 'entropy'}. Got 'ginni' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3610 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\tree\\_classes.py\", line 889, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\tree\\_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_parameters: {'criterion': 'entropy', 'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.81354586 0.88554608 0.81354586]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyper parameters for decision tree\n",
    "params = {\n",
    "    'criterion':('ginni','entropy'),\n",
    "    'splitter':('best','random'),\n",
    "    'max_depth':(list(range(1,20))),\n",
    "    'min_samples_split':(list(range(1,20))),\n",
    "    'min_samples_leaf':(list(range(1,20)))\n",
    "}\n",
    "\n",
    "rfc = DecisionTreeClassifier(random_state=23)\n",
    "rfc_cv = GridSearchCV(rfc,params,verbose=2,n_jobs=-1,cv=5,scoring='accuracy')\n",
    "\n",
    "rfc_cv.fit(x_train,y_train) # Training the data on GridSearchCV\n",
    "best_parameters = rfc_cv.best_params_ # it will give us best parameters\n",
    "# Printing the best parameters for further predictions\n",
    "print('best_parameters:',best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30ae8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcclassifier = DecisionTreeClassifier(criterion= 'entropy', max_depth= 12, min_samples_leaf= 1, min_samples_split= 13, splitter= 'best',random_state = 54)\n",
    "rfcclassifier.fit(x_train,y_train)\n",
    "y_predrfc = rfcclassifier.predict(x_test)\n",
    "y_predrfc_train = rfcclassifier.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e74cec57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.94      0.95      0.95       175\n",
      "           3       0.94      0.85      0.89       175\n",
      "           4       0.89      0.97      0.93       175\n",
      "\n",
      "    accuracy                           0.92       525\n",
      "   macro avg       0.92      0.92      0.92       525\n",
      "weighted avg       0.92      0.92      0.92       525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing Accuracy\n",
    "print(classification_report(y_test,y_predrfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "77d87576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.98      0.99      0.98       699\n",
      "           3       0.98      0.95      0.97       699\n",
      "           4       0.97      0.99      0.98       699\n",
      "\n",
      "    accuracy                           0.98      2097\n",
      "   macro avg       0.98      0.98      0.98      2097\n",
      "weighted avg       0.98      0.98      0.98      2097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Accuracy\n",
    "print(classification_report(y_train,y_predrfc_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc43db73",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27b065eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=200)\n",
    "rfc.fit(x_train,y_train)\n",
    "y_pred_rfc = rfc.predict(x_test)\n",
    "y_pred_rfctrain = rfc.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9dceef03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.91      0.97      0.94       175\n",
      "           3       0.95      0.89      0.92       175\n",
      "           4       0.98      0.97      0.97       175\n",
      "\n",
      "    accuracy                           0.94       525\n",
      "   macro avg       0.95      0.94      0.94       525\n",
      "weighted avg       0.95      0.94      0.94       525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing score\n",
    "print(classification_report(y_test,y_pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2eb68779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00       699\n",
      "           3       1.00      1.00      1.00       699\n",
      "           4       1.00      1.00      1.00       699\n",
      "\n",
      "    accuracy                           1.00      2097\n",
      "   macro avg       1.00      1.00      1.00      2097\n",
      "weighted avg       1.00      1.00      1.00      2097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training score\n",
    "print(classification_report(y_train,y_pred_rfctrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b974746",
   "metadata": {},
   "source": [
    "## Hyper parameters for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "291f8e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "60 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.95469031 0.93036481 0.93322537 0.95468917 0.95421184 0.93322537\n",
      "        nan 0.94658029 0.95898284 0.94658257 0.95325832 0.94848846\n",
      " 0.93275031 0.95802819        nan        nan 0.94896466 0.94562564\n",
      " 0.95850324        nan 0.95421298 0.96184566 0.95659734 0.95564269\n",
      " 0.95468803 0.93322537 0.91033754 0.93370383 0.91176838 0.91176725\n",
      " 0.95659848 0.93465962 0.95755199 0.92416184 0.95373565 0.90652347\n",
      "        nan 0.930841   0.94896579 0.95946017 0.94896693 0.93990567\n",
      "        nan 0.95469031 0.96470622 0.9461041  0.95182748 0.90890442\n",
      " 0.94801341 0.95278327 0.9184396  0.90890556 0.94944085 0.93370383\n",
      "        nan 0.90795318 0.95755313        nan        nan 0.92988635\n",
      " 0.90890669 0.94324355 0.93036595 0.91272304 0.9103364  0.93895102\n",
      "        nan 0.94085805 0.90986021 0.94562791 0.96327537 0.94371974\n",
      " 0.90985907 0.93417775 0.930841   0.93894988 0.93418116 0.92988635\n",
      " 0.9332265  0.94514718 0.94753267 0.93370269        nan 0.93370156\n",
      " 0.95039891 0.930841   0.93990453 0.95230481        nan 0.95612115\n",
      " 0.91129333 0.94562678 0.95039436 0.94514831 0.93751904 0.94705989\n",
      " 0.9246403  0.91939198 0.94705876 0.93322537]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'n_estimators': 600, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 18, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameters for Random Forest\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators':[400,600,800,1000,1200,1400,1600,1800,2000,2200],\n",
    "    'max_depth':(list(range(5,19))),\n",
    "    'min_samples_split':(list(range(1,9))),\n",
    "    'min_samples_leaf':(list(range(1,6))),\n",
    "    'max_features':['auto','sqrt'],\n",
    "    'bootstrap':[True,False]}\n",
    "\n",
    "Model = RandomForestClassifier(random_state=43)\n",
    "rf_tree_rcv = RandomizedSearchCV(Model,param_grid,verbose=2,n_jobs=-1,cv=5,n_iter=100,scoring='accuracy')\n",
    "\n",
    "rf_tree_rcv.fit(x_train,y_train) # Training the data on GridSearchCV\n",
    "\n",
    "best_parameters1 = rf_tree_rcv.best_params_\n",
    "# printing best parameters for further prediction\n",
    "print('best parameters:',best_parameters1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b99abcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faizaan Ali Baig\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "rfclassifier = RandomForestClassifier(n_estimators= 600, min_samples_split= 2, min_samples_leaf= 1, max_features= 'auto', max_depth= 18, bootstrap= False,random_state=32)\n",
    "rfclassifier.fit(x_train,y_train)\n",
    "y_pred_rf = rfclassifier.predict(x_test)\n",
    "y_pred_rftrain = rfclassifier.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa92c41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.92      0.98      0.95       175\n",
      "           3       0.95      0.90      0.92       175\n",
      "           4       0.98      0.97      0.97       175\n",
      "\n",
      "    accuracy                           0.95       525\n",
      "   macro avg       0.95      0.95      0.95       525\n",
      "weighted avg       0.95      0.95      0.95       525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing score\n",
    "print(classification_report(y_test,y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0578c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00       699\n",
      "           3       1.00      1.00      1.00       699\n",
      "           4       1.00      1.00      1.00       699\n",
      "\n",
      "    accuracy                           1.00      2097\n",
      "   macro avg       1.00      1.00      1.00      2097\n",
      "weighted avg       1.00      1.00      1.00      2097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training score\n",
    "print(classification_report(y_train,y_pred_rftrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728e7aec",
   "metadata": {},
   "source": [
    "**# Selecting this model for further production**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "01f42d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving this model using pickle\n",
    "import pickle\n",
    "with open('trained_model.pkl', 'wb') as file:\n",
    "    pickle.dump(rfclassifier, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e696752f",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0c1763cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB = MultinomialNB()\n",
    "NB.fit(x_train,y_train)\n",
    "y_pred_NB = NB.predict(x_test)\n",
    "y_pred_NBtrain = NB.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9de5b629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.57      0.67      0.62       175\n",
      "           3       0.62      0.47      0.54       175\n",
      "           4       0.68      0.72      0.70       175\n",
      "\n",
      "    accuracy                           0.62       525\n",
      "   macro avg       0.62      0.62      0.62       525\n",
      "weighted avg       0.62      0.62      0.62       525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing score\n",
    "print(classification_report(y_test,y_pred_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7aa83bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.57      0.58      0.57       699\n",
      "           3       0.59      0.49      0.54       699\n",
      "           4       0.66      0.76      0.70       699\n",
      "\n",
      "    accuracy                           0.61      2097\n",
      "   macro avg       0.61      0.61      0.60      2097\n",
      "weighted avg       0.61      0.61      0.60      2097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training score\n",
    "print(classification_report(y_train,y_pred_NBtrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565f682b",
   "metadata": {},
   "source": [
    "**\"We trained a model called RandomForest with its optimal settings. This model, saved as 'trained_model.pkl', is quite versatile and accurate. In another notebook, we're using it to predict outcomes for new data.\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89443520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
